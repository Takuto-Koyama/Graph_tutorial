{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GNNを用いたリンク予測\n",
        "`introduction <1_introduction>`では、GNNを用いたノード分類 (グラフ内のノードの分類を予測する) について学習した。今回は、リンク予測 (グラフ内の任意の2つのノード間のエッジの存在を予測する) にGNNを訓練する方法を学ぶ。\n",
        "\n",
        "\n",
        "このチュートリアルの目標は、以下の通りである:\n",
        "\n",
        "- GNNを用いたリンク予測モデルを構築する。\n",
        "- 小規模なDGL提供のデータセットでモデルを訓練し、評価する。\n",
        "\n",
        "(Time estimate: 28 minutes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# ライブラリのインポート\n",
        "import itertools\n",
        "import os\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "\n",
        "import dgl\n",
        "import dgl.data\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GNNを用いたリンク予測の概要\n",
        "\n",
        "social recommendationや、item recommendation、知識グラフ補完のような多くの適用例は、リンク予測として定式化できる。リンク予測は、2つの特定のノード間にエッジが存在するかどうかを予測する。このチュートリアルでは、引用ネットワーク内の2つの論文間に引用関係が存在するかどうかを予測する例を示す。\n",
        "\n",
        "このチュートリアルでは、リンク予測問題を以下のように2値分類問題として定式化する:\n",
        "\n",
        "- グラフ内のエッジを *positive examples* として扱う。\n",
        "- 存在しないエッジ (つまり、それらの間にエッジが存在しないノードペア) を *negative examples* としてサンプリングする。\n",
        "- positive examples と negative examples をトレーニングセットとテストセットに分割する。\n",
        "- 任意の2値分類メトリック (例: Area Under Curve (AUC)) でモデルを評価する。\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The practice comes from\n",
        "   [SEAL](https://papers.nips.cc/paper/2018/file/53f0d7c537d99b3824f0f99d62ea2428-Paper.pdf)_,\n",
        "   although the model here does not use their idea of node labeling.</p></div>\n",
        "\n",
        "大規模スケールのレコメンダーシステムや情報検索のようないくつかのドメインでは、上位K個の予測の良いパフォーマンスを強調するような評価指標が望ましい。この場合、平均適合率 (mean average precision) などの他の評価指標を用いてもよく、このチュートリアルの範疇を超えるが、他のネガティブサンプリング手法を適用してもよい。\n",
        "\n",
        "## グラフと特徴量の読み込み\n",
        "`introduction <1_introduction>`に引き続き、ここでもまずCoraデータセットを読み込む。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n"
          ]
        }
      ],
      "source": [
        "dataset = dgl.data.CoraGraphDataset()\n",
        "g = dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare training and testing sets\n",
        "\n",
        "## 学習セットとテストセットの準備\n",
        "\n",
        "このチュートリアルでは、テストセットのpositive examplesとしてエッジの10%をランダムに選択し、残りをトレーニングセットに残す。そして、それぞれのセットに同じ数のnegative examplesをサンプリングする。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# エッジセットをトレーニングとテストに分割する\n",
        "u, v = g.edges()\n",
        "\n",
        "eids = np.arange(g.num_edges())\n",
        "eids = np.random.permutation(eids)\n",
        "test_size = int(len(eids) * 0.1)\n",
        "train_size = g.num_edges() - test_size\n",
        "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
        "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
        "\n",
        "# すべての負例のエッジを見つけ、トレーニングとテストに分割します\n",
        "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy()))) # 隣接行列を作成 -> 補足A\n",
        "adj_neg = 1 - adj.todense() - np.eye(g.num_nodes()) # 隣接行列の補集合を作成 -> 補足B\n",
        "neg_u, neg_v = np.where(adj_neg != 0)\n",
        "\n",
        "neg_eids = np.random.choice(len(neg_u), g.num_edges()) # 負例のエッジをランダムに選択\n",
        "test_neg_u, test_neg_v = (\n",
        "    neg_u[neg_eids[:test_size]],\n",
        "    neg_v[neg_eids[:test_size]],\n",
        ")\n",
        "train_neg_u, train_neg_v = (\n",
        "    neg_u[neg_eids[test_size:]],\n",
        "    neg_v[neg_eids[test_size:]],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 補足A 隣接行列の作成\n",
        "\n",
        "`scipy.sparse.coo_matrix`では、value, (row, col)の形式でデータを入力することで、(row, col)の位置にvalueを代入した疎行列を作成できる。今回はエッジのインデックスを(u, v)に与えるため、`scipy.sparse.coo_matrix`を使って隣接行列を作成する。\n",
        "```python\n",
        "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
        "```\n",
        "\n",
        "### 補足B 隣接行列の反転\n",
        "`adj_neg`では、隣接行列`adj`が反転された行列が作成される。具体的には、1 - `adj`で隣接行列が反転され、 `-np.eye(num_nodes)`で対角成分が0になるように調整される。\n",
        "```python\n",
        "adj_neg = 1 - adj.todense() - np.eye(g.num_nodes())\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "学習するときは、テストセットのエッジを元のグラフから削除する必要がある。これは``dgl.remove_edges``を使って行うことができる。\n",
        "\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>\n",
        "   ``dgl.remove_edges``は元のグラフからサブグラフを作成することで動作するので、コピーが作成されることにより大規模なグラフでは遅くなる可能性がある。その場合は、前処理と同様にトレーニンググラフとテストグラフをディスクに保存してもよい。</p></div>\n",
        "   \n",
        "   </p></div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_g = dgl.remove_edges(g, eids[:test_size]) # テストエッジを削除"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GraphSAGEモデルの定義\n",
        "このチュートリアルでは、2つの[GraphSAGE](https://arxiv.org/abs/1706.02216)層からなるモデルを構築する。  \n",
        "各層は、隣接情報を平均して新しいノード表現を計算する。DGLは、GraphSAGE層を簡単に作成する``dgl.nn.SAGEConv``を提供する。  \n",
        "\n",
        "SAGEConvは、`3_messgae_passing`で既に自作しているが、今回はDGLの`SAGEConv`を使用する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from dgl.nn import SAGEConv\n",
        "\n",
        "\n",
        "# ----------- 2. create model -------------- #\n",
        "# build a two-layer GraphSAGE model\n",
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, h_feats, \"mean\")\n",
        "        self.conv2 = SAGEConv(h_feats, h_feats, \"mean\")\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "モデルは、両端のノードの表現間のスコアを計算することで、エッジの存在確率を予測する。スコアは、両ノードの特徴量を用いた関数 (例: MLPまたは内積)で計算される。\n",
        "\n",
        "\\begin{align}\\hat{y}_{u\\sim v} = f(h_u, h_v)\\end{align}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ポジティブグラフ、ネガティブグラフ、および``apply_edges``\n",
        "\n",
        "前回のチュートリアルでは、GNNを用いてノード表現を計算する方法を学習した。しかし、リンク予測では、*ノードのペア*の表現を計算する必要がある。  \n",
        "\n",
        "\n",
        "DGLは、ノードのペアをエッジとして表現できるため、ノードのペアを別のグラフとして扱うことを推奨している。リンク予測では、すべてのpositive examplesをエッジとして持つ*positive graph*と、すべてのnegative examplesを持つ*negative graph*がある。*positive graph*と*negative graph*は、元のグラフと同じノードセットを持つ。これにより、複数のグラフ間でノード特徴量を簡単に渡すことができる。後で見るように、全体のグラフで計算されたノード表現を直接positive graphとnegative graphに渡して、ペアごとのスコアを計算することができる。\n",
        "\n",
        "以下のコードは、それぞれのトレーニングセットとテストセットに対して、positive graphとnegative graphを構築する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.num_nodes())\n",
        "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.num_nodes())\n",
        "\n",
        "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.num_nodes())\n",
        "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.num_nodes())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ノードのペアをグラフとして扱う利点は、``DGLGraph.apply_edges``メソッドを使用できることである。  \n",
        "このメソッドは、便利に、インシデントノードの特徴量と元のエッジの特徴量 (適用可能な場合) に基づいて新しいエッジ特徴量を計算する。\n",
        "\n",
        "\n",
        "DGLは、元のノード/エッジ特徴量に基づいて新しいエッジ特徴量を計算するための最適化された組み込み関数を提供している。  \n",
        "例えば、``dgl.function.u_dot_v``は、各エッジのインシデントノードの表現の内積を計算する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import dgl.function as fn\n",
        "\n",
        "# 内積を計算するためのカスタムエッジ予測器\n",
        "class DotPredictor(nn.Module):\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h  # ノード特徴量を追加。hはノードの特徴量を表すテンソル\n",
        "            # 'score' という新しいエッジ特徴量を計算する。これは、ソースノードの特徴量 'h' とターゲットノードの特徴量 'h' の内積によって計算される。\n",
        "            g.apply_edges(fn.u_dot_v(\"h\", \"h\", \"score\"))\n",
        "            # u_dot_v は各エッジに対して1要素のベクトルを返すため、それをsqueezeする必要がある\n",
        "            return g.edata[\"score\"][:, 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "自分で関数を書くこともできる。\n",
        "例えば、次のモジュールは、インシデントノードの特徴量を連結してMLPに渡し、各エッジにスカラースコアを生成する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class MLPPredictor(nn.Module):\n",
        "    def __init__(self, h_feats):\n",
        "        super().__init__()\n",
        "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
        "        self.W2 = nn.Linear(h_feats, 1)\n",
        "\n",
        "    def apply_edges(self, edges):\n",
        "        \"\"\"\n",
        "        Computes a scalar score for each edge of the given graph.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        edges :\n",
        "            Has three members ``src``, ``dst`` and ``data``, each of\n",
        "            which is a dictionary representing the features of the\n",
        "            source nodes, the destination nodes, and the edges\n",
        "            themselves.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dict\n",
        "            A dictionary of new edge features.\n",
        "        \"\"\"\n",
        "        h = torch.cat([edges.src[\"h\"], edges.dst[\"h\"]], 1) # ソースノードとターゲットノードの特徴量を連結\n",
        "        return {\"score\": self.W2(F.relu(self.W1(h))).squeeze(1)} # 2つの線形層を通過し、スカラースコアを返す\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            g.apply_edges(self.apply_edges)\n",
        "            return g.edata[\"score\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>\n",
        "   ビルトイン関数は、速度とメモリの両方に最適化されているため、可能な限りビルトイン関数を使用することを推奨する。</p></div>\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>\n",
        "   :`message passing tutorial <3_message_passing>` を読んだことがある場合、\n",
        "   ``apply_edges``の引数は、``update_all``のメッセージ関数とまったく同じ形式であることがわかるだろう。</p></div>\n",
        "   </p></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 学習ループ\n",
        "\n",
        "ノード表現の計算とエッジスコアの計算を定義したら、モデル全体、損失関数、評価メトリックを定義する。\n",
        "\n",
        "\n",
        "損失関数は、単純なバイナリ交差エントロピー損失である。\n",
        "\n",
        "\\begin{align}\\mathcal{L} = -\\sum_{u\\sim v\\in \\mathcal{D}}\\left( y_{u\\sim v}\\log(\\hat{y}_{u\\sim v}) + (1-y_{u\\sim v})\\log(1-\\hat{y}_{u\\sim v})) \\right)\\end{align}\n",
        "\n",
        "\n",
        "評価指標は、このチュートリアルではAUCを用いる。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = GraphSAGE(train_g.ndata[\"feat\"].shape[1], 16)\n",
        "# DotPredictor と MLPPredictor を置き換えることができる。\n",
        "# pred = MLPPredictor(16)\n",
        "pred = DotPredictor()\n",
        "\n",
        "\n",
        "def compute_loss(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat(\n",
        "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
        "    )\n",
        "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "\n",
        "def compute_auc(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
        "    labels = torch.cat(\n",
        "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
        "    ).numpy()\n",
        "    return roc_auc_score(labels, scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "学習ループは以下の通りである:\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>\n",
        "   このチュートリアルにはバリデーションセットでの評価が含まれていません。実際には、バリデーションセットでのパフォーマンスに基づいて最良のモデルを保存して評価する必要がある。</p></div>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In epoch 0, loss: 0.25840190052986145\n",
            "In epoch 5, loss: 0.25079312920570374\n",
            "In epoch 10, loss: 0.24637673795223236\n",
            "In epoch 15, loss: 0.23924537003040314\n",
            "In epoch 20, loss: 0.2313515990972519\n",
            "In epoch 25, loss: 0.2229684591293335\n",
            "In epoch 30, loss: 0.2141314297914505\n",
            "In epoch 35, loss: 0.20476028323173523\n",
            "In epoch 40, loss: 0.19516490399837494\n",
            "In epoch 45, loss: 0.18557053804397583\n",
            "In epoch 50, loss: 0.17561843991279602\n",
            "In epoch 55, loss: 0.16514258086681366\n",
            "In epoch 60, loss: 0.1545877754688263\n",
            "In epoch 65, loss: 0.14387385547161102\n",
            "In epoch 70, loss: 0.1331481635570526\n",
            "In epoch 75, loss: 0.12258487194776535\n",
            "In epoch 80, loss: 0.11222700774669647\n",
            "In epoch 85, loss: 0.10211115330457687\n",
            "In epoch 90, loss: 0.09234435111284256\n",
            "In epoch 95, loss: 0.08299131691455841\n",
            "AUC 0.8109826823296871\n"
          ]
        }
      ],
      "source": [
        "# ----------- 3. set up loss and optimizer -------------- #\n",
        "# 今回は、損失は学習ループ内で計算される\n",
        "optimizer = torch.optim.Adam(\n",
        "    itertools.chain(model.parameters(), pred.parameters()), lr=0.01\n",
        ")\n",
        "\n",
        "# ----------- 4. training -------------------------------- #\n",
        "all_logits = []\n",
        "for e in range(100):\n",
        "    # forward\n",
        "    h = model(train_g, train_g.ndata[\"feat\"])\n",
        "    pos_score = pred(train_pos_g, h)\n",
        "    neg_score = pred(train_neg_g, h)\n",
        "    loss = compute_loss(pos_score, neg_score)\n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if e % 5 == 0:\n",
        "        print(\"In epoch {}, loss: {}\".format(e, loss))\n",
        "\n",
        "# ----------- 5. check results ------------------------ #\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "with torch.no_grad():\n",
        "    pos_score = pred(test_pos_g, h)\n",
        "    neg_score = pred(test_neg_g, h)\n",
        "    print(\"AUC\", compute_auc(pos_score, neg_score))\n",
        "\n",
        "\n",
        "# Thumbnail credits: Link Prediction with Neo4j, Mark Needham\n",
        "# sphinx_gallery_thumbnail_path = '_static/blitz_4_link_predict.png'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
