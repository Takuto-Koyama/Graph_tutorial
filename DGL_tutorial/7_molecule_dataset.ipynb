{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分子データセットの作成とGCNの学習\n",
    "\n",
    "このチュートリアルでは、`6_load_data`の拡張として、分子データセットを作成し、GCNで学習する。\n",
    "\n",
    "事前に以下のライブラリをインストールする。dgllifeはライフサイエンス向けのdglライブラリで、化学・生物分野におけるグラフデータを扱うのに有用である。\n",
    "```bash\n",
    "pip install dgllife\n",
    "pip install rdkit-pypi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from dgllife.utils import BaseAtomFeaturizer, atom_type_one_hot, atom_degree_one_hot, atom_total_num_H_one_hot, \\\n",
    "        atom_is_aromatic_one_hot, atom_hybridization_one_hot, atom_formal_charge_one_hot, atom_num_radical_electrons_one_hot, \\\n",
    "        bond_type_one_hot, bond_is_conjugated_one_hot, bond_is_in_ring_one_hot, bond_stereo_one_hot, BaseBondFeaturizer, ConcatFeaturizer\n",
    "except:\n",
    "    !pip install dgllife\n",
    "    from dgllife.utils import BaseAtomFeaturizer, atom_type_one_hot, atom_degree_one_hot, atom_total_num_H_one_hot, \\\n",
    "        atom_is_aromatic_one_hot, atom_hybridization_one_hot, atom_formal_charge_one_hot, atom_num_radical_electrons_one_hot, \\\n",
    "        bond_type_one_hot, bond_is_conjugated_one_hot, bond_is_in_ring_one_hot, bond_stereo_one_hot, BaseBondFeaturizer, ConcatFeaturizer\n",
    "\n",
    "try:\n",
    "    from rdkit import Chem\n",
    "except:\n",
    "    !pip install rdkit-pypi\n",
    "    from rdkit import Chem\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from dgl.data import DGLDataset\n",
    "from dgllife.utils import smiles_to_bigraph\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurizerの実装\n",
    "\n",
    "Featurizerの実装には、``dgllife.utils``に実装されている関数を使用する。各関数は、分子の特徴量を計算するための関数であるが、グラフのノードおよびエッジに特徴量として保持するために、各関数をリスト化したものを``ConcatFeaturizer``に入力する。これにより各関数の出力を連結したものを特徴量として出力することが可能である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_feats_funcs = [atom_type_one_hot, \n",
    "                    atom_degree_one_hot,\n",
    "                    atom_total_num_H_one_hot,\n",
    "                    atom_is_aromatic_one_hot,\n",
    "                    atom_hybridization_one_hot,\n",
    "                    atom_formal_charge_one_hot,\n",
    "                    atom_num_radical_electrons_one_hot,\n",
    "                    ]\n",
    "\n",
    "bond_feats_funcs = [bond_type_one_hot,\n",
    "                    bond_is_conjugated_one_hot,\n",
    "                    bond_is_in_ring_one_hot,\n",
    "                    bond_stereo_one_hot,\n",
    "                    ]\n",
    "\n",
    "# ConcatFeaturizerにより、特徴量を連結する\n",
    "atom_concat_featurizer = ConcatFeaturizer(atom_feats_funcs)\n",
    "bond_concat_featurizer = ConcatFeaturizer(bond_feats_funcs)\n",
    "\n",
    "# BaseAtomFeaturizer, BaseBondFeaturizerを用いて、特徴量を作成する\n",
    "mol_atom_featurizer = BaseAtomFeaturizer({'h': atom_concat_featurizer})\n",
    "mol_bond_featurizer = BaseBondFeaturizer({'e': bond_concat_featurizer})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "サンプルとして、ベンゼン``'c1ccccc1'``で特徴量を計算する。原子特徴量は (6, 76), 結合特徴量は (12, 14) のテンソルとして出力される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atom feature: torch.Size([6, 76])\n",
      "bond feature: torch.Size([12, 14])\n"
     ]
    }
   ],
   "source": [
    "smi = 'c1ccccc1'\n",
    "mol = Chem.MolFromSmiles(smi)\n",
    "atom_feats_ex = mol_atom_featurizer(mol)\n",
    "bond_feats_ex = mol_bond_featurizer(mol)\n",
    "print(\"atom feature:\", atom_feats_ex['h'].size())\n",
    "print(\"bond feature:\", bond_feats_ex['e'].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMILESからグラフの構築\n",
    "smilesからグラフを構築するには、[```SMILESToBigraph```](https://lifesci.dgl.ai/generated/dgllife.utils.smiles_to_bigraph.html)を使用する。molオブジェクトから作成する場合、[```MolToBigraph```](https://lifesci.dgl.ai/generated/dgllife.utils.MolToBigraph.html)が使える。  \n",
    "例としてエタノール``'CCO'``をグラフに変換する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=3, num_edges=4,\n",
       "      ndata_schemes={'h': Scheme(shape=(76,), dtype=torch.float32)}\n",
       "      edata_schemes={'e': Scheme(shape=(14,), dtype=torch.float32)})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smi = 'CCO'\n",
    "g = smiles_to_bigraph(smi, node_featurizer=mol_atom_featurizer,\n",
    "                      edge_featurizer=mol_bond_featurizer)\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DGLDatasetの作成\n",
    "次に、DGLDatasetの作成をする。基本的なDGLDatasetの作成方法は``6_load_data.ipynb``を参照できるが、ここでは割愛する。今回は、[ZINC-250K](https://www.kaggle.com/datasets/basu369victor/zinc250k)のデータセットを使用する。簡単のため、今回は1000化合物のみを使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>logP</th>\n",
       "      <th>qed</th>\n",
       "      <th>SAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>247668</th>\n",
       "      <td>CC(C)(C)OC(=O)N1CCC[C@H]1/C([O-])=N/S(C)(=O)=O</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.544834</td>\n",
       "      <td>3.420845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180273</th>\n",
       "      <td>O=C(CC[NH2+][C@@H](c1ccc(F)cc1)C1CCCC1)N1CCCC1</td>\n",
       "      <td>2.63290</td>\n",
       "      <td>0.856875</td>\n",
       "      <td>3.391335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68403</th>\n",
       "      <td>CN(Cc1ccncc1)C(=O)CCNS(C)(=O)=O</td>\n",
       "      <td>-0.02070</td>\n",
       "      <td>0.811294</td>\n",
       "      <td>2.134847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48774</th>\n",
       "      <td>COc1ncnc(N2CCC[C@H]2C2CCCC2)c1N</td>\n",
       "      <td>2.22640</td>\n",
       "      <td>0.906907</td>\n",
       "      <td>2.968756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21866</th>\n",
       "      <td>C[C@H](NC(=O)NCC(C)(C)[NH+](C)C)c1ccc(C(F)(F)F...</td>\n",
       "      <td>1.98870</td>\n",
       "      <td>0.762620</td>\n",
       "      <td>3.469637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70310</th>\n",
       "      <td>COc1cc2nc([S-])n(Cc3ccc(N(C)C)cc3)c(=O)c2cc1OC</td>\n",
       "      <td>2.43380</td>\n",
       "      <td>0.507814</td>\n",
       "      <td>2.600695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233706</th>\n",
       "      <td>COc1ccc(N(C)S(=O)(=O)C2Cc3ccccc3C2)cc1OC</td>\n",
       "      <td>2.63720</td>\n",
       "      <td>0.831497</td>\n",
       "      <td>2.449949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59652</th>\n",
       "      <td>COc1cccc(CNC(=O)c2cccc(C)c2C)c1O</td>\n",
       "      <td>2.94764</td>\n",
       "      <td>0.899310</td>\n",
       "      <td>1.812122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204014</th>\n",
       "      <td>Cc1cc(-c2cc(F)cc3c2O[C@H](CNC(=O)c2ccco2)C3)ccc1F</td>\n",
       "      <td>4.26672</td>\n",
       "      <td>0.716957</td>\n",
       "      <td>2.896143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234302</th>\n",
       "      <td>O=C(CCCc1nc2ccccc2s1)Nc1ccc2c(c1)COC2</td>\n",
       "      <td>4.28790</td>\n",
       "      <td>0.723958</td>\n",
       "      <td>2.248759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   smiles     logP       qed  \\\n",
       "247668     CC(C)(C)OC(=O)N1CCC[C@H]1/C([O-])=N/S(C)(=O)=O  0.10430  0.544834   \n",
       "180273     O=C(CC[NH2+][C@@H](c1ccc(F)cc1)C1CCCC1)N1CCCC1  2.63290  0.856875   \n",
       "68403                     CN(Cc1ccncc1)C(=O)CCNS(C)(=O)=O -0.02070  0.811294   \n",
       "48774                     COc1ncnc(N2CCC[C@H]2C2CCCC2)c1N  2.22640  0.906907   \n",
       "21866   C[C@H](NC(=O)NCC(C)(C)[NH+](C)C)c1ccc(C(F)(F)F...  1.98870  0.762620   \n",
       "...                                                   ...      ...       ...   \n",
       "70310      COc1cc2nc([S-])n(Cc3ccc(N(C)C)cc3)c(=O)c2cc1OC  2.43380  0.507814   \n",
       "233706           COc1ccc(N(C)S(=O)(=O)C2Cc3ccccc3C2)cc1OC  2.63720  0.831497   \n",
       "59652                    COc1cccc(CNC(=O)c2cccc(C)c2C)c1O  2.94764  0.899310   \n",
       "204014  Cc1cc(-c2cc(F)cc3c2O[C@H](CNC(=O)c2ccco2)C3)ccc1F  4.26672  0.716957   \n",
       "234302              O=C(CCCc1nc2ccccc2s1)Nc1ccc2c(c1)COC2  4.28790  0.723958   \n",
       "\n",
       "             SAS  \n",
       "247668  3.420845  \n",
       "180273  3.391335  \n",
       "68403   2.134847  \n",
       "48774   2.968756  \n",
       "21866   3.469637  \n",
       "...          ...  \n",
       "70310   2.600695  \n",
       "233706  2.449949  \n",
       "59652   1.812122  \n",
       "204014  2.896143  \n",
       "234302  2.248759  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrameの作成\n",
    "df_molecule = pd.read_csv(\"250k_rndm_zinc_drugs_clean_3.csv\")\n",
    "df_molecule[\"smiles\"] = df_molecule[\"smiles\"].apply(lambda smi: smi.replace(\"\\n\", \"\"))\n",
    "df_molecule = df_molecule.sample(n=1000, random_state=0) # 1000化合物のみ使用\n",
    "df_molecule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は、`MoleculeDataset`クラスを作成する。このクラスは、`DGLDataset`クラスを継承し、`__init__`メソッドでデータセットを読み込む。`process`メソッドでは、`__init__`の際に呼び出される、グラフセットとラベルを作成するための処理関数である。`__getitem__`メソッドはpytorchのDatasetと同じくインデックスを指定してデータを取得する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculeDataset(DGLDataset):\n",
    "    def __init__(self, df_molecule, target_columns=['logP'], num_process: int=8):\n",
    "        self.df_molecule = df_molecule\n",
    "        self.smiles = df_molecule[\"smiles\"]\n",
    "        self.labels = np.array(df_molecule[target_columns])\n",
    "        self.num_process = num_process\n",
    "        super().__init__(name=\"molecule\")\n",
    "    \n",
    "    def mp_smiles_to_graph(self, args):\n",
    "        smi = args[0]\n",
    "        node_featurizer = args[1]\n",
    "        edge_featurizer = args[2]\n",
    "        g = smiles_to_bigraph(smi, \n",
    "            node_featurizer=mol_atom_featurizer,\n",
    "            edge_featurizer=mol_bond_featurizer)\n",
    "        return g\n",
    "        \n",
    "    def process(self):\n",
    "        self.graphs = []\n",
    "        # 並列化\n",
    "        pool = multiprocessing.Pool(processes=self.num_process)\n",
    "        \n",
    "        args_list = [(smi, mol_atom_featurizer, mol_bond_featurizer) for smi in self.smiles]\n",
    "        self.graphs = pool.map(self.mp_smiles_to_graph, args_list)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        \n",
    "        self.labels = torch.tensor(self.labels, dtype=torch.float32)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.graphs[i], self.labels[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=19, num_edges=38,\n",
      "      ndata_schemes={'h': Scheme(shape=(76,), dtype=torch.float32)}\n",
      "      edata_schemes={'e': Scheme(shape=(14,), dtype=torch.float32)}) tensor([0.1043])\n"
     ]
    }
   ],
   "source": [
    "# データセットの作成\n",
    "dataset = MoleculeDataset(df_molecule)\n",
    "# 一つ目のデータを取り出す\n",
    "graph, label = dataset[0]\n",
    "print(graph, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの分割\n",
    "\n",
    "学習のために上記のデータセットを分割する。今回では、化合物データセットでよく用いられる方法である[`ScaffolfSplitter`](https://lifesci.dgl.ai/api/utils.splitters.html)を採用する。この方法は、化合物の骨格構造を基準にデータを分割する方法である。\n",
    "\n",
    "他にもいくつか、分割手法が実装されている。詳細は[こちら](https://lifesci.dgl.ai/api/utils.splitters.html)を参照。\n",
    "- ConsecutiveSplitter\n",
    "- RandomSplitter\n",
    "- MolecularWeightSplitter\n",
    "- ScaffoldSplitter\n",
    "- SingleTaskStratifiedSplitter\n",
    "\n",
    "Splitterを使うときは、`k_fold_splitメソッド`あるいは`train_valid_test_split`メソッドを使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgllife.utils import ScaffoldSplitter\n",
    "splitter = ScaffoldSplitter()\n",
    "train_dataset, valid_dataset, test_dataset = splitter.train_val_test_split(dataset, frac_val=0.1, frac_test=0.1)\n",
    "print(len(train_dataset), len(valid_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaderの作成\n",
    "`GraphDataLoader`を利用して、DataLoaderを作成する。GraphDataLoaderはPytorchのDataLoaderを拡張したものであり、要領としてはPytorchのDataLoaderと同じである。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.dataloading import GraphDataLoader\n",
    "train_loader = GraphDataLoader(\n",
    "    dataset, batch_size=16, drop_last=False, shuffle=True\n",
    ")\n",
    "\n",
    "valid_loader = GraphDataLoader(\n",
    "    dataset, batch_size=16, drop_last=False, shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = GraphDataLoader(\n",
    "    dataset, batch_size=16, drop_last=False, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AttentiveFPの実装\n",
    "\n",
    "次にGNNモデルの実装をする。今回は、dgllifeに実装されている`AttentiveFPGNN`モジュールを使用する。`AttentiveFPGNN`で出力されるテンソルはノードごとの特徴量であるので、これを集約するために、`dgl.mean_nodes(g, \"h\")`で特徴量の平均化を行う (cf. readout)。これにより、グラフ全体の特徴量を得ることができる。出力されたグラフ特徴量は、`MLP`レイヤに通して最終的な予測を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgllife.model.gnn.attentivefp import AttentiveFPGNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "    \n",
    "class AttentiveFP(nn.Module):\n",
    "    def __init__(self, node_feat_size=76, edge_feat_size=14, \n",
    "                       num_layers=2, graph_feat_size=256, dropout=0.2, num_classes=1):\n",
    "        super(AttentiveFP, self).__init__()\n",
    "        self.attentive_fp = AttentiveFPGNN(\n",
    "            node_feat_size=node_feat_size, edge_feat_size=edge_feat_size, num_layers=num_layers,\n",
    "            graph_feat_size=graph_feat_size, dropout=dropout,\n",
    "        )\n",
    "        \n",
    "        self.mlp = MLP(in_feats=256, h_feats=128, num_classes=1)\n",
    "    \n",
    "    def forward(self, g, node_feats, edge_feats):\n",
    "        graph_feature = self.attentive_fp(g, node_feats, edge_feats)\n",
    "        g.ndata[\"h\"] = graph_feature\n",
    "        mean_feature = dgl.mean_nodes(g, \"h\")\n",
    "        out = self.mlp(mean_feature)\n",
    "        return out\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_feats, h_feats)\n",
    "        self.lin2 = nn.Linear(h_feats, h_feats)\n",
    "        self.out = nn.Linear(h_feats, num_classes)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.activation(self.lin1(x))\n",
    "        x2 = self.activation(self.lin2(x1) + x1)\n",
    "        out = self.out(x2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 　学習の実行\n",
    "最後に学習ループの実装を行い、実行する。dgllifeには性能評価のためのモジュールとして`Meter`クラスが実装されているので、今回はこれを使用する。\n",
    "`Meter`オブジェクトは、`compute_metric(metric_name, reduction)`で指定したメトリックを計算することができる。詳細は[こちら](https://lifesci.dgl.ai/generated/dgllife.utils.Meter.html)を参照。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Epoch: 1\n",
      "Train RMSE: 1.5678720474243164\n",
      "Validation RMSE: 1.2511006593704224\n",
      "==================================================\n",
      "Epoch: 2\n",
      "Train RMSE: 1.4290059804916382\n",
      "Validation RMSE: 1.2390072345733643\n",
      "==================================================\n",
      "Epoch: 3\n",
      "Train RMSE: 1.3600316047668457\n",
      "Validation RMSE: 1.1795523166656494\n",
      "==================================================\n",
      "Epoch: 4\n",
      "Train RMSE: 1.2824602127075195\n",
      "Validation RMSE: 1.1023876667022705\n",
      "==================================================\n",
      "Epoch: 5\n",
      "Train RMSE: 1.200405478477478\n",
      "Validation RMSE: 1.0481113195419312\n",
      "==================================================\n",
      "Epoch: 6\n",
      "Train RMSE: 1.1318678855895996\n",
      "Validation RMSE: 0.995769202709198\n",
      "==================================================\n",
      "Epoch: 7\n",
      "Train RMSE: 1.0768791437149048\n",
      "Validation RMSE: 0.947625994682312\n",
      "==================================================\n",
      "Epoch: 8\n",
      "Train RMSE: 1.0328803062438965\n",
      "Validation RMSE: 0.9112719297409058\n",
      "==================================================\n",
      "Epoch: 9\n",
      "Train RMSE: 0.9929183721542358\n",
      "Validation RMSE: 0.8764486312866211\n",
      "==================================================\n",
      "Epoch: 10\n",
      "Train RMSE: 0.9580897092819214\n",
      "Validation RMSE: 0.8472912311553955\n",
      "==================================================\n",
      "Epoch: 11\n",
      "Train RMSE: 0.9278594255447388\n",
      "Validation RMSE: 0.8214513063430786\n",
      "==================================================\n",
      "Epoch: 12\n",
      "Train RMSE: 0.9020091891288757\n",
      "Validation RMSE: 0.7994392514228821\n",
      "==================================================\n",
      "Epoch: 13\n",
      "Train RMSE: 0.8779982328414917\n",
      "Validation RMSE: 0.7807252407073975\n",
      "==================================================\n",
      "Epoch: 14\n",
      "Train RMSE: 0.8564057350158691\n",
      "Validation RMSE: 0.7669174671173096\n",
      "==================================================\n",
      "Epoch: 15\n",
      "Train RMSE: 0.838862955570221\n",
      "Validation RMSE: 0.7501415014266968\n",
      "==================================================\n",
      "Epoch: 16\n",
      "Train RMSE: 0.8223546147346497\n",
      "Validation RMSE: 0.7353468537330627\n",
      "==================================================\n",
      "Epoch: 17\n",
      "Train RMSE: 0.8063321113586426\n",
      "Validation RMSE: 0.7209856510162354\n",
      "==================================================\n",
      "Epoch: 18\n",
      "Train RMSE: 0.7913302183151245\n",
      "Validation RMSE: 0.7075700163841248\n",
      "==================================================\n",
      "Epoch: 19\n",
      "Train RMSE: 0.7801070213317871\n",
      "Validation RMSE: 0.6982084512710571\n",
      "==================================================\n",
      "Epoch: 20\n",
      "Train RMSE: 0.767520010471344\n",
      "Validation RMSE: 0.6913201212882996\n",
      "==================================================\n",
      "Epoch: 21\n",
      "Train RMSE: 0.7566774487495422\n",
      "Validation RMSE: 0.6810365915298462\n",
      "==================================================\n",
      "Epoch: 22\n",
      "Train RMSE: 0.7456728219985962\n",
      "Validation RMSE: 0.672029435634613\n",
      "==================================================\n",
      "Epoch: 23\n",
      "Train RMSE: 0.7352486252784729\n",
      "Validation RMSE: 0.6627145409584045\n",
      "==================================================\n",
      "Epoch: 24\n",
      "Train RMSE: 0.7256573438644409\n",
      "Validation RMSE: 0.6541728377342224\n",
      "==================================================\n",
      "Epoch: 25\n",
      "Train RMSE: 0.716387152671814\n",
      "Validation RMSE: 0.6465893983840942\n",
      "==================================================\n",
      "Epoch: 26\n",
      "Train RMSE: 0.7073897123336792\n",
      "Validation RMSE: 0.6388291716575623\n",
      "==================================================\n",
      "Epoch: 27\n",
      "Train RMSE: 0.6989425420761108\n",
      "Validation RMSE: 0.6315308809280396\n",
      "==================================================\n",
      "Epoch: 28\n",
      "Train RMSE: 0.6912355422973633\n",
      "Validation RMSE: 0.6250385046005249\n",
      "==================================================\n",
      "Epoch: 29\n",
      "Train RMSE: 0.6837494373321533\n",
      "Validation RMSE: 0.618558943271637\n",
      "==================================================\n",
      "Epoch: 30\n",
      "Train RMSE: 0.6767905354499817\n",
      "Validation RMSE: 0.6135934591293335\n",
      "==================================================\n",
      "Epoch: 31\n",
      "Train RMSE: 0.6699827313423157\n",
      "Validation RMSE: 0.6072947382926941\n",
      "==================================================\n",
      "Epoch: 32\n",
      "Train RMSE: 0.6633020639419556\n",
      "Validation RMSE: 0.6018088459968567\n",
      "==================================================\n",
      "Epoch: 33\n",
      "Train RMSE: 0.6581405401229858\n",
      "Validation RMSE: 0.5962347984313965\n",
      "==================================================\n",
      "Epoch: 34\n",
      "Train RMSE: 0.6522048711776733\n",
      "Validation RMSE: 0.5908881425857544\n",
      "==================================================\n",
      "Epoch: 35\n",
      "Train RMSE: 0.6463698148727417\n",
      "Validation RMSE: 0.5858319997787476\n",
      "==================================================\n",
      "Epoch: 36\n",
      "Train RMSE: 0.6409255266189575\n",
      "Validation RMSE: 0.581030547618866\n",
      "==================================================\n",
      "Epoch: 37\n",
      "Train RMSE: 0.6355254650115967\n",
      "Validation RMSE: 0.577029287815094\n",
      "==================================================\n",
      "Epoch: 38\n",
      "Train RMSE: 0.6301373839378357\n",
      "Validation RMSE: 0.5721659660339355\n",
      "==================================================\n",
      "Epoch: 39\n",
      "Train RMSE: 0.6249955296516418\n",
      "Validation RMSE: 0.5677376389503479\n",
      "==================================================\n",
      "Epoch: 40\n",
      "Train RMSE: 0.6202808022499084\n",
      "Validation RMSE: 0.5633963346481323\n",
      "==================================================\n",
      "Epoch: 41\n",
      "Train RMSE: 0.616030752658844\n",
      "Validation RMSE: 0.5598080158233643\n",
      "==================================================\n",
      "Epoch: 42\n",
      "Train RMSE: 0.6114990711212158\n",
      "Validation RMSE: 0.5556837916374207\n",
      "==================================================\n",
      "Epoch: 43\n",
      "Train RMSE: 0.6072648763656616\n",
      "Validation RMSE: 0.5522230267524719\n",
      "==================================================\n",
      "Epoch: 44\n",
      "Train RMSE: 0.6029947996139526\n",
      "Validation RMSE: 0.5488153696060181\n",
      "==================================================\n",
      "Epoch: 45\n",
      "Train RMSE: 0.5987155437469482\n",
      "Validation RMSE: 0.5449387431144714\n",
      "==================================================\n",
      "Epoch: 46\n",
      "Train RMSE: 0.5944958329200745\n",
      "Validation RMSE: 0.5409833788871765\n",
      "==================================================\n",
      "Epoch: 47\n",
      "Train RMSE: 0.5903633832931519\n",
      "Validation RMSE: 0.5378325581550598\n",
      "==================================================\n",
      "Epoch: 48\n",
      "Train RMSE: 0.5864912867546082\n",
      "Validation RMSE: 0.5340240597724915\n",
      "==================================================\n",
      "Epoch: 49\n",
      "Train RMSE: 0.5826243758201599\n",
      "Validation RMSE: 0.5308182835578918\n",
      "==================================================\n",
      "Epoch: 50\n",
      "Train RMSE: 0.5788757801055908\n",
      "Validation RMSE: 0.5274519920349121\n",
      "Test RMSE: 0.32194235920906067\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "from dgllife.utils import Meter\n",
    "import dgl\n",
    "# Create the model with given dimensions\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = AttentiveFP(node_feat_size=76, edge_feat_size=14, \n",
    "                    num_layers=2, graph_feat_size=256, dropout=0.2, num_classes=1).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criteria = nn.MSELoss()\n",
    "\n",
    "train_meter, valid_meter, test_meter = Meter(), Meter(), Meter()\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    for batched_graph, labels in train_loader:\n",
    "        batched_graph, labels = batched_graph.to(device), labels.to(device)\n",
    "        pred = model(batched_graph, batched_graph.ndata[\"h\"], batched_graph.edata['e'])\n",
    "        loss = criteria(pred, labels)\n",
    "        train_meter.update(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_rmse = train_meter.compute_metric('rmse', reduction='mean')\n",
    "    print(f\"Train RMSE: {train_rmse}\")    \n",
    "    \n",
    "    model.eval()\n",
    "    for batched_graph, labels in valid_loader:\n",
    "        batched_graph, labels = batched_graph.to(device), labels.to(device)\n",
    "        pred = model(batched_graph, batched_graph.ndata[\"h\"], batched_graph.edata['e'])\n",
    "        valid_meter.update(pred, labels)\n",
    "    valid_rmse = valid_meter.compute_metric('rmse', reduction='mean')\n",
    "    print(f\"Validation RMSE: {valid_rmse}\")\n",
    "\n",
    "\n",
    "model.eval()\n",
    "for batched_graph, labels in test_loader:\n",
    "    batched_graph, labels = batched_graph.to(device), labels.to(device)\n",
    "    pred = model(batched_graph, batched_graph.ndata[\"h\"], batched_graph.edata['e'])\n",
    "    test_meter.update(pred, labels)\n",
    "test_rmse = test_meter.compute_metric('rmse', reduction='mean')\n",
    "print(f\"Test RMSE: {test_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
